{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "from pyspark import *\n",
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from collections import defaultdict\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the Dataset to use delete comment mark (#) from it \n",
    "Example- If u wanna select Bike sharing Dataset , remove # from File = 'hour.csv' and other places where code is commented\n",
    "\n",
    "The code will create noheader file according to dataset so we need to change the dataset name in Decision Tree Code only\n",
    "and remove # from required code in Gradient Boosted and Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'TourneyDetailedResults.csv'\n",
    "#file = '2017.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a file noheader.csv by removing the headers from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (file,'rb') as inp:\n",
    "    with open('noheader_Tourney.csv','wb') as out:\n",
    "        inp.readline()\n",
    "        for line in inp:\n",
    "            out.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First record:  ['1', '2011-01-01', '1', '0', '1', '0', '0', '6', '0', '1', '0.24', '0.2879', '0.81', '0', '3', '13', '16']\n",
      "Total number of records:  17379\n"
     ]
    }
   ],
   "source": [
    "path = \"noheader.csv\"\n",
    "raw_data = sc.textFile(path)\n",
    "num_data = raw_data.count()\n",
    "records = raw_data.map(lambda x: x.split(\",\"))\n",
    "first = records.first()\n",
    "print('First record: ', first)\n",
    "print('Total number of records: ', num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[4] at RDD at PythonRDD.scala:49"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapping(rdd, idx):\n",
    "    return rdd.map(lambda fields: fields[idx]).distinct().zipWithIndex().collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of first categorical feature column: {'1': 0, '4': 1, '2': 2, '3': 3}\n"
     ]
    }
   ],
   "source": [
    "print(\"Mapping of first categorical feature column: %s\" % get_mapping(records, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = [get_mapping(records, i) for i in range(2,10)]\n",
    "#mappings = [get_mapping(records, i) for i in range(2,3)]\n",
    "cat_len = sum((len(b) for b in mappings))\n",
    "num_len = len(records.first()[11:15])\n",
    "#num_len = len(records.first()[3:11])\n",
    "total_len = num_len + cat_len\n",
    "cat_fea = reduce(lambda a, b: dict(a,**b), mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector length for categorical features: 57\n",
      "Feature vector length for numerical features: 4\n",
      "Total feature vector length: 61\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature vector length for categorical features: %d\" % cat_len)\n",
    "print(\"Feature vector length for numerical features: %d\" % num_len)\n",
    "print(\"Total feature vector length: %d\" % total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_dt(record):\n",
    "    return np.array(record[2:14])\n",
    "    #return np.array(record[3:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(record):\n",
    "    return float(record[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dt = records.map(lambda r: LabeledPoint(extract_label(r), extract_features_dt(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Label: 16.0\n",
      "Decision Tree feature vector: [1.0,0.0,1.0,0.0,0.0,6.0,0.0,1.0,0.24,0.2879,0.81,0.0]\n",
      "Decision Tree feature vector length: 12\n"
     ]
    }
   ],
   "source": [
    "first_point = data_dt.first()\n",
    "print(\"Decision Tree Label: \" + str(first_point.label))\n",
    "print(\"Decision Tree feature vector: \" + str(first_point.features))\n",
    "print(\"Decision Tree feature vector length: \" + str(len(first_point.features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree prediction:[(16.0, 54.913223140495866), (40.0, 54.913223140495866), (32.0, 53.171052631578945), (13.0, 14.284023668639053), (1.0, 14.284023668639053)]\n",
      "Decision Tree depth: 5\n",
      "Decision Tree number of nodes: 63\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTree.trainRegressor(data_dt, categoricalFeaturesInfo={})\n",
    "preds = dt_model.predict(data_dt.map(lambda p: p.features))\n",
    "actual = data_dt.map(lambda p: p.label)\n",
    "true_vs_predicted_dt = actual.zip(preds)\n",
    "print(\"Decision tree prediction:\" +str(true_vs_predicted_dt.take(5)))\n",
    "print(\"Decision Tree depth: \" + str(dt_model.depth()))\n",
    "print(\"Decision Tree number of nodes: \" + str(dt_model.numNodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root Suarred Error\n",
    "def squared_log_error(pred, actual):\n",
    "    return (np.log(pred + 1) - np.log(actual + 1))**2\n",
    "\n",
    "# Aboslute Error\n",
    "def abs_error(actual, pred):\n",
    "     return np.abs(pred - actual)\n",
    "# Mean Squared Error     \n",
    "def squared_error(actual, pred):\n",
    "    return (pred - actual)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle_dt = np.sqrt(true_vs_predicted_dt.map(lambda lp: squared_log_error(lp[0], lp[1])).mean())\n",
    "mse = true_vs_predicted_dt.map(lambda lp: squared_error(lp[0], lp[1])).mean()\n",
    "mae = true_vs_predicted_dt.map(lambda lp: abs_error(lp[0], lp[1])).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model - Root Mean Squared Log Error: 0.6251\n",
      "Decision Tree Model - Mean Squared Error: 11611.4860\n",
      "Decision Tree Model - Mean Absolute Error: 71.1502\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Model - Root Mean Squared Log Error: %2.4f\" % rmsle_dt)\n",
    "print(\"Decision Tree Model - Mean Squared Error: %2.4f\" % mse)\n",
    "print(\"Decision Tree Model - Mean Absolute Error: %2.4f\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model - Root Mean Squared Log Error: 0.6343\n",
      "Decision Tree Model - Mean Squared Error: 12705.6879\n",
      "Decision Tree Model - Mean Absolute Error: 73.3905\n"
     ]
    }
   ],
   "source": [
    "def extract_features_dt_c(record):\n",
    "    return np.array(record[2:10])\n",
    "    \n",
    "def extract_label_c(record):\n",
    "    return float(record[-1])\n",
    "\n",
    "data_dt_c = records.map(lambda r: LabeledPoint(extract_label_c(r), extract_features_dt_c(r)))\n",
    "dt_model_c = DecisionTree.trainRegressor(data_dt_c, categoricalFeaturesInfo={})\n",
    "preds_c = dt_model_c.predict(data_dt_c.map(lambda p: p.features))\n",
    "actual_c = data_dt_c.map(lambda p: p.label)\n",
    "true_vs_predicted_dt_c = actual_c.zip(preds_c)\n",
    "mse_c = true_vs_predicted_dt_c.map(lambda lp: squared_error(lp[0], lp[1])).mean()\n",
    "mae_c = true_vs_predicted_dt_c.map(lambda lp: abs_error(lp[0], lp[1])).mean()\n",
    "rmsle_dt_c = np.sqrt(true_vs_predicted_dt_c.map(lambda lp: squared_log_error(lp[0], lp[1])).mean())\n",
    "\n",
    "\n",
    "print(\"Decision Tree Categorical Features - Mean Squared Error: %2.4f\" % mse_c)\n",
    "print(\"Decision Tree Categorical Features - Mean Absolute Error: %2.4f\" % mae_c)\n",
    "print(\"Decision Tree Categorical Features - Root Mean Squared Log Error: %2.4f\" % rmsle_dt_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = records.map(lambda r: float(r[-1])).collect()\n",
    "hist(targets, bins=40, color='lightblue', normed=True)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(16,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_targets = records.map(lambda r: np.log(float(r[-1]))).collect()\n",
    "hist(log_targets, bins=40, color='lightblue', normed=True)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(16,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_targets = records.map(lambda r: np.sqrt(float(r[-1]))).collect()\n",
    "hist(sqrt_targets, bins=40, color='lightblue', normed=True)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(16,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dt_log = data_dt.map(lambda lp:LabeledPoint(np.log(lp.label), lp.features))\n",
    "dt_model_log = DecisionTree.trainRegressor(data_dt_log,categoricalFeaturesInfo={})\n",
    "preds_log = dt_model_log.predict(data_dt_log.map(lambda p:p.features))\n",
    "actual_log = data_dt_log.map(lambda p: p.label)\n",
    "true_vs_predicted_dt_log = actual_log.zip(preds_log).map(lambda p: (np.exp(p[0]), np.exp(p[1])))\n",
    "mse_log_dt = true_vs_predicted_dt_log.map(lambda p: squared_error(p[0], p[1])).mean()\n",
    "mae_log_dt = true_vs_predicted_dt_log.map(lambda p: abs_error(p[0], p[1])).mean()\n",
    "rmsle_log_dt = np.sqrt(true_vs_predicted_dt_log.map(lambda p:squared_log_error(p[0], p[1])).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Decision Tree Log - Mean Squared Error: %2.4f\" % mse_log_dt)\n",
    "print (\"Decision Tree Log - Mean Absolue Error: %2.4f\" % mae_log_dt)\n",
    "print (\"Decision Tree Log - Root Mean Squared Log Error: %2.4f\" % rmsle_log_dt)\n",
    "print (\"Decision Tree Log - Non log-transformed predictions:\" +str(true_vs_predicted_dt.take(3)))\n",
    "print (\"Decision Tree Log - Log-transformed predictions:\" +str(true_vs_predicted_dt_log.take(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data into Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_idx_dt = data_dt.zipWithIndex().map(lambda p: (p[1],p[0]))\n",
    "test_dt = data_with_idx_dt.sample(False, 0.2, 42)\n",
    "train_dt = data_with_idx_dt.subtractByKey(test_dt)\n",
    "train_data_dt = train_dt.map(lambda p: p[1])\n",
    "test_data_dt = test_dt.map(lambda p: p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dt(train, test, maxDepth, maxBins):\n",
    "    model = DecisionTree.trainRegressor(train, categoricalFeaturesInfo={},impurity='variance', maxDepth=maxDepth, maxBins=maxBins)\n",
    "    preds = model.predict(test.map(lambda p: p.features))\n",
    "    actual = test.map(lambda p: p.label)\n",
    "    tp = actual.zip(preds)\n",
    "    rmsle = np.sqrt(tp.map(lambda p: squared_log_error(p[0], p[1])).mean())\n",
    "    return rmsle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Max Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [2, 4, 8, 16, 32, 64, 100]\n",
    "metrics = [evaluate_dt(train_data_dt, test_data_dt, 5, param) for param in params]\n",
    "print (params)\n",
    "print (metrics)\n",
    "plot(params, metrics)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "plt.xlabel('Max Bins')\n",
    "plt.ylabel('RMSLE')\n",
    "plt.title('Decision Trees - Max Bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Max Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [1, 2, 3, 4, 5, 10, 20]\n",
    "metrics = [evaluate_dt(train_data_dt, test_data_dt, param, 32) for param in params]\n",
    "print (params)\n",
    "print (metrics)\n",
    "plot(params, metrics)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('RMSLE')\n",
    "plt.title('Decision Trees - Max Depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
